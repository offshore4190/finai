"""
æµ‹è¯•HTMLæ–‡ä»¶å†…å®¹ï¼ŒéªŒè¯å›¾ç‰‡é“¾æ¥é‡å†™
æ£€æŸ¥æ‰€æœ‰ <img> æ ‡ç­¾çš„ src å±æ€§æ˜¯å¦å·²ä»åŸå§‹ URL é‡å†™ä¸ºæœ¬åœ°ç›¸å¯¹è·¯å¾„

ä½¿ç”¨æ–¹æ³•ï¼š
  python test_html_image_rewrite.py                      # æµ‹è¯•æ‰€æœ‰HTMLæ–‡ä»¶
  python test_html_image_rewrite.py --sample 50          # éšæœºæŠ½æ ·50ä¸ªæ–‡ä»¶æµ‹è¯•
  python test_html_image_rewrite.py --exchange NASDAQ    # åªæµ‹è¯•NASDAQ
  python test_html_image_rewrite.py --company AAPL       # åªæµ‹è¯•ç‰¹å®šå…¬å¸
  python test_html_image_rewrite.py --verbose            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
"""

import argparse
import re
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple
import random

from bs4 import BeautifulSoup
from config.settings import settings


class HTMLImageRewriteTester:
    """HTMLå›¾ç‰‡é“¾æ¥é‡å†™æµ‹è¯•å™¨"""
    
    def __init__(self, verbose: bool = False):
        self.storage_root = Path(settings.storage_root)
        self.verbose = verbose
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_files': 0,
            'files_with_images': 0,
            'total_img_tags': 0,
            'rewritten_correctly': 0,
            'not_rewritten': 0,
            'invalid_format': 0,
            'errors': 0
        }
        
        # é—®é¢˜è®°å½•
        self.issues = defaultdict(list)
        
    def is_sec_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯SECçš„URL"""
        if not url:
            return False
        return 'sec.gov' in url.lower() or url.startswith('http://') or url.startswith('https://')
    
    def is_local_relative_path(self, path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°ç›¸å¯¹è·¯å¾„"""
        if not path:
            return False
        # åº”è¯¥æ˜¯ ./imageXX.png æˆ– imageXX.png æ ¼å¼
        return (path.startswith('./') or not path.startswith(('http://', 'https://', '/'))) and \
               ('image' in path.lower() or path.endswith(('.png', '.jpg', '.jpeg', '.gif')))
    
    def check_html_file(self, html_path: Path) -> Dict:
        """æ£€æŸ¥å•ä¸ªHTMLæ–‡ä»¶"""
        result = {
            'path': str(html_path.relative_to(self.storage_root)),
            'img_count': 0,
            'rewritten': 0,
            'not_rewritten': 0,
            'sec_urls': [],
            'local_paths': [],
            'other_urls': []
        }
        
        try:
            with open(html_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # ä½¿ç”¨ BeautifulSoup è§£æ
            soup = BeautifulSoup(content, 'html.parser')
            img_tags = soup.find_all('img')
            
            result['img_count'] = len(img_tags)
            
            for img in img_tags:
                src = img.get('src', '')
                
                if not src:
                    continue
                
                if self.is_sec_url(src):
                    # æœªé‡å†™ï¼Œä»ç„¶æ˜¯SEC URL
                    result['not_rewritten'] += 1
                    result['sec_urls'].append(src)
                    self.stats['not_rewritten'] += 1
                elif self.is_local_relative_path(src):
                    # å·²é‡å†™ä¸ºæœ¬åœ°ç›¸å¯¹è·¯å¾„
                    result['rewritten'] += 1
                    result['local_paths'].append(src)
                    self.stats['rewritten_correctly'] += 1
                else:
                    # å…¶ä»–æ ¼å¼ï¼ˆå¯èƒ½æ˜¯data:, æˆ–å…¶ä»–ï¼‰
                    result['other_urls'].append(src)
            
            self.stats['total_img_tags'] += result['img_count']
            if result['img_count'] > 0:
                self.stats['files_with_images'] += 1
            
            return result
            
        except Exception as e:
            result['error'] = str(e)
            self.stats['errors'] += 1
            return result
    
    def scan_html_files(self, exchange: str = None, company: str = None, sample_size: int = None) -> List[Path]:
        """æ‰«æHTMLæ–‡ä»¶"""
        print(f"ğŸ“ æ‰«æHTMLæ–‡ä»¶...")
        
        if not self.storage_root.exists():
            print(f"âš ï¸  å­˜å‚¨ç›®å½•ä¸å­˜åœ¨: {self.storage_root}")
            return []
        
        html_files = []
        
        # éå†ç›®å½•ç»“æ„
        for exchange_dir in self.storage_root.iterdir():
            if not exchange_dir.is_dir():
                continue
            
            # å¦‚æœæŒ‡å®šäº†äº¤æ˜“æ‰€ï¼Œè·³è¿‡å…¶ä»–äº¤æ˜“æ‰€
            if exchange and exchange_dir.name != exchange:
                continue
            
            for company_dir in exchange_dir.iterdir():
                if not company_dir.is_dir():
                    continue
                
                # å¦‚æœæŒ‡å®šäº†å…¬å¸ï¼Œè·³è¿‡å…¶ä»–å…¬å¸
                if company and company_dir.name.upper() != company.upper():
                    continue
                
                # æŸ¥æ‰¾æ‰€æœ‰HTMLæ–‡ä»¶
                for html_file in company_dir.rglob('*.html'):
                    html_files.append(html_file)
                for htm_file in company_dir.rglob('*.htm'):
                    html_files.append(htm_file)
        
        # å¦‚æœæŒ‡å®šäº†æŠ½æ ·å¤§å°
        if sample_size and len(html_files) > sample_size:
            html_files = random.sample(html_files, sample_size)
        
        print(f"âœ… æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
        return html_files
    
    def run_test(self, exchange: str = None, company: str = None, sample_size: int = None):
        """è¿è¡Œæµ‹è¯•"""
        print("\n" + "=" * 100)
        print("ğŸ§ª HTMLå›¾ç‰‡é“¾æ¥é‡å†™æµ‹è¯•")
        print("=" * 100 + "\n")
        
        # æ‰«æHTMLæ–‡ä»¶
        html_files = self.scan_html_files(exchange, company, sample_size)
        
        if not html_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°HTMLæ–‡ä»¶")
            return
        
        self.stats['total_files'] = len(html_files)
        
        print(f"\nå¼€å§‹æ£€æŸ¥ {len(html_files)} ä¸ªHTMLæ–‡ä»¶...\n")
        
        # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
        problem_files = []
        
        for i, html_path in enumerate(html_files, 1):
            if i % 100 == 0 or self.verbose:
                print(f"  è¿›åº¦: {i}/{len(html_files)}")
            
            result = self.check_html_file(html_path)
            
            # è®°å½•æœ‰é—®é¢˜çš„æ–‡ä»¶
            if result['not_rewritten'] > 0:
                problem_files.append(result)
                self.issues['not_rewritten'].append(result)
            
            if 'error' in result:
                self.issues['errors'].append(result)
            
            # å¦‚æœæ˜¯verboseæ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if self.verbose and result['img_count'] > 0:
                print(f"\næ–‡ä»¶: {result['path']}")
                print(f"  å›¾ç‰‡æ€»æ•°: {result['img_count']}")
                print(f"  å·²é‡å†™: {result['rewritten']}")
                print(f"  æœªé‡å†™: {result['not_rewritten']}")
                
                if result['sec_urls']:
                    print(f"  æœªé‡å†™çš„SEC URLç¤ºä¾‹:")
                    for url in result['sec_urls'][:3]:
                        print(f"    - {url}")
        
        # æ‰“å°æµ‹è¯•æŠ¥å‘Š
        self.print_report(problem_files)
    
    def print_report(self, problem_files: List[Dict]):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 100)
        print("ğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print("=" * 100 + "\n")
        
        print("ã€æ€»ä½“ç»Ÿè®¡ã€‘")
        print(f"  æµ‹è¯•æ–‡ä»¶æ•°: {self.stats['total_files']:,}")
        print(f"  åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶: {self.stats['files_with_images']:,}")
        print(f"  å›¾ç‰‡æ ‡ç­¾æ€»æ•°: {self.stats['total_img_tags']:,}")
        print(f"  å·²æ­£ç¡®é‡å†™: {self.stats['rewritten_correctly']:,}")
        print(f"  æœªé‡å†™ï¼ˆä»æ˜¯SEC URLï¼‰: {self.stats['not_rewritten']:,}")
        print(f"  å¤„ç†é”™è¯¯: {self.stats['errors']:,}")
        
        # è®¡ç®—é‡å†™ç‡
        if self.stats['total_img_tags'] > 0:
            rewrite_rate = (self.stats['rewritten_correctly'] / self.stats['total_img_tags']) * 100
            print(f"\n  âœ¨ é‡å†™ç‡: {rewrite_rate:.2f}%")
        
        print("\n" + "-" * 100)
        
        # å¦‚æœæœ‰é—®é¢˜æ–‡ä»¶ï¼Œæ˜¾ç¤ºè¯¦æƒ…
        if problem_files:
            print(f"\nâš ï¸  å‘ç° {len(problem_files)} ä¸ªæ–‡ä»¶å­˜åœ¨æœªé‡å†™çš„å›¾ç‰‡é“¾æ¥\n")
            
            print("ã€é—®é¢˜æ–‡ä»¶åˆ—è¡¨ã€‘ï¼ˆå‰20ä¸ªï¼‰")
            for i, result in enumerate(problem_files[:20], 1):
                print(f"\n{i}. æ–‡ä»¶: {result['path']}")
                print(f"   å›¾ç‰‡æ€»æ•°: {result['img_count']}, æœªé‡å†™: {result['not_rewritten']}")
                
                if result['sec_urls']:
                    print(f"   æœªé‡å†™çš„URLç¤ºä¾‹:")
                    for url in result['sec_urls'][:2]:
                        print(f"     - {url}")
            
            if len(problem_files) > 20:
                print(f"\n... è¿˜æœ‰ {len(problem_files) - 20} ä¸ªé—®é¢˜æ–‡ä»¶æœªåˆ—å‡º")
        else:
            print("\nâœ… æ‰€æœ‰HTMLæ–‡ä»¶çš„å›¾ç‰‡é“¾æ¥éƒ½å·²æ­£ç¡®é‡å†™ä¸ºæœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼")
        
        # å¦‚æœæœ‰é”™è¯¯
        if self.stats['errors'] > 0:
            print(f"\nâš ï¸  å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿ {self.stats['errors']} ä¸ªé”™è¯¯")
            print("ã€é”™è¯¯æ–‡ä»¶ã€‘ï¼ˆå‰10ä¸ªï¼‰")
            for i, result in enumerate(self.issues['errors'][:10], 1):
                print(f"{i}. {result['path']}: {result.get('error', 'Unknown error')}")
        
        print("\n" + "=" * 100)
        
        # ç»™å‡ºç»“è®º
        if self.stats['not_rewritten'] == 0 and self.stats['errors'] == 0:
            print("ğŸ‰ æµ‹è¯•é€šè¿‡ï¼æ‰€æœ‰å›¾ç‰‡é“¾æ¥éƒ½å·²æ­£ç¡®é‡å†™ã€‚")
        elif self.stats['not_rewritten'] > 0:
            print(f"âŒ æµ‹è¯•å¤±è´¥ï¼šå‘ç° {self.stats['not_rewritten']} ä¸ªæœªé‡å†™çš„å›¾ç‰‡é“¾æ¥ã€‚")
        else:
            print(f"âš ï¸  æµ‹è¯•å®Œæˆï¼Œä½†æœ‰ {self.stats['errors']} ä¸ªæ–‡ä»¶å¤„ç†é”™è¯¯ã€‚")
        
        print("=" * 100 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æµ‹è¯•HTMLæ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥é‡å†™',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æµ‹è¯•æ‰€æœ‰HTMLæ–‡ä»¶
  python test_html_image_rewrite.py
  
  # éšæœºæŠ½æ ·50ä¸ªæ–‡ä»¶æµ‹è¯•
  python test_html_image_rewrite.py --sample 50
  
  # åªæµ‹è¯•NASDAQäº¤æ˜“æ‰€
  python test_html_image_rewrite.py --exchange NASDAQ
  
  # åªæµ‹è¯•ç‰¹å®šå…¬å¸
  python test_html_image_rewrite.py --company AAPL
  
  # è¯¦ç»†æ¨¡å¼
  python test_html_image_rewrite.py --sample 10 --verbose
        """
    )
    
    parser.add_argument(
        '--exchange',
        type=str,
        help='æŒ‡å®šäº¤æ˜“æ‰€ï¼ˆå¦‚ï¼šNASDAQ, NYSEï¼‰'
    )
    
    parser.add_argument(
        '--company',
        type=str,
        help='æŒ‡å®šå…¬å¸tickerï¼ˆå¦‚ï¼šAAPL, TSLAï¼‰'
    )
    
    parser.add_argument(
        '--sample',
        type=int,
        help='éšæœºæŠ½æ ·çš„æ–‡ä»¶æ•°é‡'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥BeautifulSoupæ˜¯å¦å¯ç”¨
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        print("âŒ é”™è¯¯ï¼šéœ€è¦å®‰è£… beautifulsoup4")
        print("   è¿è¡Œ: pip install beautifulsoup4")
        return 1
    
    # è¿è¡Œæµ‹è¯•
    tester = HTMLImageRewriteTester(verbose=args.verbose)
    tester.run_test(
        exchange=args.exchange,
        company=args.company,
        sample_size=args.sample
    )
    
    # æ ¹æ®ç»“æœè¿”å›é€€å‡ºç 
    if tester.stats['not_rewritten'] > 0:
        return 1
    return 0


if __name__ == '__main__':
    sys.exit(main())

